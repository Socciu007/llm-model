{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\test\\chatbot\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "f:\\test\\chatbot\\env\\Lib\\site-packages\\transformers\\deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"facebook/hf-seamless-m4t-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Áp dụng lượng tử hóa động\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./quantized_model\\\\tokenizer_config.json',\n",
       " './quantized_model\\\\special_tokens_map.json',\n",
       " './quantized_model\\\\sentencepiece.bpe.model',\n",
       " './quantized_model\\\\added_tokens.json',\n",
       " './quantized_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./quantized_model\"\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Lưu mô hình lượng tử hóa\n",
    "torch.save(quantized_model.state_dict(), os.path.join(output_dir, \"quantized_model.pth\"))\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải lại mô hình lượng tử hóa\n",
    "model_path = os.path.join(output_dir, \"quantized_model.pth\")\n",
    "quantized_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Tải lại tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\test\\chatbot\\env\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import io\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_tensor(audio_segment):\n",
    "    \"\"\"Chuyển đổi AudioSegment thành tensor\"\"\"\n",
    "    audio_array = np.array(audio_segment.get_array_of_samples())\n",
    "    return torch.tensor(audio_array).float().unsqueeze(0)  # Thêm dimension cho batch\n",
    "\n",
    "def tensor_to_audio(tensor):\n",
    "    \"\"\"Chuyển đổi tensor thành AudioSegment\"\"\"\n",
    "    audio_array = tensor.squeeze().numpy()\n",
    "    return AudioSegment(\n",
    "        audio_array.tobytes(), \n",
    "        frame_rate=44100, \n",
    "        sample_width=audio_array.dtype.itemsize, \n",
    "        channels=1\n",
    "    )\n",
    "\n",
    "def text_to_speech(text):\n",
    "    \"\"\"Chuyển văn bản thành giọng nói\"\"\"\n",
    "    from pyttsx3 import init\n",
    "    engine = init()\n",
    "    output_path = 'output.wav'\n",
    "    engine.save_to_file(text, output_path)\n",
    "    engine.runAndWait()\n",
    "    return AudioSegment.from_file(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải âm thanh từ file và chuyển đổi\n",
    "input_file = \"path/to/input_audio.wav\"\n",
    "audio = AudioSegment.from_file(input_file)\n",
    "audio_tensor = audio_to_tensor(audio)\n",
    "\n",
    "# Xử lý âm thanh qua mô hình\n",
    "inputs = tokenizer(audio_tensor, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs['input_ids'])\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Chuyển văn bản thành giọng nói\n",
    "output_audio = text_to_speech(output_text)\n",
    "\n",
    "# Lưu và phát âm thanh đầu ra\n",
    "output_audio.export(\"output_speech.wav\", format=\"wav\")\n",
    "output_audio.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
